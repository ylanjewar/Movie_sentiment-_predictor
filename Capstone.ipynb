{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb977be1-f459-4e91-a78c-fcc20729774c",
   "metadata": {},
   "source": [
    "Capstone Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ade1e24-6723-4486-a5e9-fcdb27aa05f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.8892\n",
      "Precision: 0.8827694728560189\n",
      "Recall: 0.8976\n",
      "F1 Score: 0.8901229670765569\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4404  596]\n",
      " [ 512 4488]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89      5000\n",
      "           1       0.88      0.90      0.89      5000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n",
      "\n",
      "Model: Support Vector Machine\n",
      "Accuracy: 0.8864\n",
      "Precision: 0.8807646826960978\n",
      "Recall: 0.8938\n",
      "F1 Score: 0.8872344649593011\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4395  605]\n",
      " [ 531 4469]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89      5000\n",
      "           1       0.88      0.89      0.89      5000\n",
      "\n",
      "    accuracy                           0.89     10000\n",
      "   macro avg       0.89      0.89      0.89     10000\n",
      "weighted avg       0.89      0.89      0.89     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"data/imdb.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Check dataset structure\n",
    "df.head()\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove punctuation and special characters\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])  # Remove stopwords\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing\n",
    "df['review'] = df['review'].apply(preprocess_text)\n",
    "\n",
    "# Convert sentiment labels to numeric\n",
    "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "# Split dataset into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.2, random_state=42, stratify=df['sentiment'])\n",
    "\n",
    "# Convert text to TF-IDF vectors\n",
    "tfidf = TfidfVectorizer(max_features=5000)  # Limit to 5000 most common words\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Initialize models\n",
    "log_reg = LogisticRegression()\n",
    "svm = SVC(kernel='linear')\n",
    "\n",
    "# Train Logistic Regression\n",
    "log_reg.fit(X_train_tfidf, y_train)\n",
    "y_pred_log = log_reg.predict(X_test_tfidf)\n",
    "\n",
    "# Train SVM\n",
    "svm.fit(X_train_tfidf, y_train)\n",
    "y_pred_svm = svm.predict(X_test_tfidf)\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "    print(\"Recall:\", recall_score(y_true, y_pred))\n",
    "    print(\"F1 Score:\", f1_score(y_true, y_pred))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Evaluate both models\n",
    "evaluate_model(y_test, y_pred_log, \"Logistic Regression\")\n",
    "evaluate_model(y_test, y_pred_svm, \"Support Vector Machine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be05b42b-9a3e-444c-9796-51f89c689570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.8979\n",
      "Precision: 0.892483724600513\n",
      "Recall: 0.9048\n",
      "F1 Score: 0.8985996623299235\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4455  545]\n",
      " [ 476 4524]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.90      5000\n",
      "           1       0.89      0.90      0.90      5000\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "\n",
      "Model: Support Vector Machine\n",
      "Accuracy: 0.9046\n",
      "Precision: 0.899171270718232\n",
      "Recall: 0.9114\n",
      "F1 Score: 0.9052443384982122\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4489  511]\n",
      " [ 443 4557]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90      5000\n",
      "           1       0.90      0.91      0.91      5000\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"data/imdb.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Check dataset structure\n",
    "df.head()\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove punctuation and special characters\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing\n",
    "df['review'] = df['review'].apply(preprocess_text)\n",
    "\n",
    "# Convert sentiment labels to numeric\n",
    "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "# Split dataset into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.2, random_state=42, stratify=df['sentiment'])\n",
    "\n",
    "# Convert text to TF-IDF vectors with bigrams and increased feature size\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=20000)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Initialize models with optimized hyperparameters\n",
    "log_reg = LogisticRegression(C=0.5)\n",
    "svm = SVC(kernel='linear', C=0.5)\n",
    "\n",
    "# Train Logistic Regression\n",
    "log_reg.fit(X_train_tfidf, y_train)\n",
    "y_pred_log = log_reg.predict(X_test_tfidf)\n",
    "\n",
    "# Train SVM\n",
    "svm.fit(X_train_tfidf, y_train)\n",
    "y_pred_svm = svm.predict(X_test_tfidf)\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "    print(\"Recall:\", recall_score(y_true, y_pred))\n",
    "    print(\"F1 Score:\", f1_score(y_true, y_pred))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Evaluate both models\n",
    "evaluate_model(y_test, y_pred_log, \"Logistic Regression\")\n",
    "evaluate_model(y_test, y_pred_svm, \"Support Vector Machine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d49b13-47ce-4485-b939-3700ed5315f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3785c3b-3aa1-44d6-b193-2a1e2dd45066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.8979\n",
      "Precision: 0.892483724600513\n",
      "Recall: 0.9048\n",
      "F1 Score: 0.8985996623299235\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4455  545]\n",
      " [ 476 4524]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.89      0.90      5000\n",
      "           1       0.89      0.90      0.90      5000\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "\n",
      "Model: Support Vector Machine\n",
      "Accuracy: 0.9046\n",
      "Precision: 0.899171270718232\n",
      "Recall: 0.9114\n",
      "F1 Score: 0.9052443384982122\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4489  511]\n",
      " [ 443 4557]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.90      0.90      5000\n",
      "           1       0.90      0.91      0.91      5000\n",
      "\n",
      "    accuracy                           0.90     10000\n",
      "   macro avg       0.90      0.90      0.90     10000\n",
      "weighted avg       0.90      0.90      0.90     10000\n",
      "\n",
      "Review: I absolutely loved this movie! The story was amazing and the acting was brilliant.\n",
      "Logistic Regression Prediction: Positive\n",
      "SVM Prediction: Positive\n",
      "\n",
      "Review: Worst movie ever. It was a complete waste of time.\n",
      "Logistic Regression Prediction: Negative\n",
      "SVM Prediction: Negative\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"data/imdb.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Check dataset structure\n",
    "df.head()\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove punctuation and special characters\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing\n",
    "df['review'] = df['review'].apply(preprocess_text)\n",
    "\n",
    "# Convert sentiment labels to numeric\n",
    "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "\n",
    "# Split dataset into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.2, random_state=42, stratify=df['sentiment'])\n",
    "\n",
    "# Convert text to TF-IDF vectors with bigrams and increased feature size\n",
    "tfidf = TfidfVectorizer(ngram_range=(1,2), max_features=20000)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Save the TF-IDF vectorizer\n",
    "with open(\"tfidf_vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tfidf, f)\n",
    "\n",
    "# Initialize models with optimized hyperparameters\n",
    "log_reg = LogisticRegression(C=0.5)\n",
    "svm = SVC(kernel='linear', C=0.5)\n",
    "\n",
    "# Train Logistic Regression\n",
    "log_reg.fit(X_train_tfidf, y_train)\n",
    "y_pred_log = log_reg.predict(X_test_tfidf)\n",
    "\n",
    "# Train SVM\n",
    "svm.fit(X_train_tfidf, y_train)\n",
    "y_pred_svm = svm.predict(X_test_tfidf)\n",
    "\n",
    "# Save trained models\n",
    "with open(\"logistic_regression.pkl\", \"wb\") as f:\n",
    "    pickle.dump(log_reg, f)\n",
    "\n",
    "with open(\"svm_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(svm, f)\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "    print(\"Recall:\", recall_score(y_true, y_pred))\n",
    "    print(\"F1 Score:\", f1_score(y_true, y_pred))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "# Evaluate both models\n",
    "evaluate_model(y_test, y_pred_log, \"Logistic Regression\")\n",
    "evaluate_model(y_test, y_pred_svm, \"Support Vector Machine\")\n",
    "\n",
    "# Function to predict sentiment for new reviews\n",
    "def predict_sentiment(new_reviews):\n",
    "    # Load vectorizer and models\n",
    "    with open(\"tfidf_vectorizer.pkl\", \"rb\") as f:\n",
    "        tfidf = pickle.load(f)\n",
    "    with open(\"logistic_regression.pkl\", \"rb\") as f:\n",
    "        log_reg = pickle.load(f)\n",
    "    with open(\"svm_model.pkl\", \"rb\") as f:\n",
    "        svm = pickle.load(f)\n",
    "    \n",
    "    # Preprocess new reviews\n",
    "    new_reviews_cleaned = [preprocess_text(review) for review in new_reviews]\n",
    "    new_reviews_tfidf = tfidf.transform(new_reviews_cleaned)\n",
    "    \n",
    "    # Predict using both models\n",
    "    predictions_log = log_reg.predict(new_reviews_tfidf)\n",
    "    predictions_svm = svm.predict(new_reviews_tfidf)\n",
    "    \n",
    "    # Display results\n",
    "    for review, sentiment_log, sentiment_svm in zip(new_reviews, predictions_log, predictions_svm):\n",
    "        print(f\"Review: {review}\")\n",
    "        print(f\"Logistic Regression Prediction: {'Positive' if sentiment_log == 1 else 'Negative'}\")\n",
    "        print(f\"SVM Prediction: {'Positive' if sentiment_svm == 1 else 'Negative'}\\n\")\n",
    "\n",
    "# Example predictions\n",
    "new_reviews = [\n",
    "    \"I absolutely loved this movie! The story was amazing and the acting was brilliant.\",\n",
    "    \"Worst movie ever. It was a complete waste of time.\"\n",
    "]\n",
    "predict_sentiment(new_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f53b04c-b808-445e-bfcf-eccf6620ef42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Delighting in razzle-dazzle over historical precision, Gladiator II rigorously entertains all the better for it.\n",
      "Logistic Regression Prediction: Negative\n",
      "SVM Prediction: Negative\n",
      "\n",
      "Review: Echoing its predecessor while upping the bloodsport and camp, Gladiator II is an action extravaganza that derives much of its strength and honor from Denzel Washington's scene-stealing performance.\n",
      "Logistic Regression Prediction: Positive\n",
      "SVM Prediction: Positive\n",
      "\n",
      "Review: Watching Gladiator II, it is hard not to be a little suspicious about exactly what we are longing for in our Roman fantasies.\n",
      "Logistic Regression Prediction: Positive\n",
      "SVM Prediction: Positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_reviews = [\n",
    "    \"Delighting in razzle-dazzle over historical precision, Gladiator II rigorously entertains all the better for it.\",  \"Echoing its predecessor while upping the bloodsport and camp, Gladiator II is an action extravaganza that derives much of its strength and honor from Denzel Washington's scene-stealing performance.\",\n",
    "    \"Watching Gladiator II, it is hard not to be a little suspicious about exactly what we are longing for in our Roman fantasies.\"\n",
    "]\n",
    "predict_sentiment(new_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfed13d5-e308-4add-b3ce-d9d465efa216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
